{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from collections import namedtuple\n",
    "from collections import defaultdict\n",
    "import cmath\n",
    "import glob\n",
    "import math\n",
    "%matplotlib inline\n",
    "\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Camera:\n",
    "    def __init__(self, src, dst):\n",
    "        self.ret = None\n",
    "        self.mtx = None\n",
    "        self.dist = None\n",
    "        self.rvecs = None\n",
    "        self.tvecs = None\n",
    "        self.src = src\n",
    "        self.dst = dst\n",
    "        \n",
    "    def compute_camera_calibration(self, images, nx, ny):\n",
    "        \"\"\"\n",
    "        Computes camera calibration matrix.\n",
    "\n",
    "        images - set of chess images \n",
    "        nx  number of corners in axis\n",
    "        ny number of corners in y axis\n",
    "        \"\"\"\n",
    "\n",
    "        objpoints = []\n",
    "        imgpoints = []\n",
    "\n",
    "        # Prepare object points as vector of vectors of points of type Point3f\n",
    "        # in the format (0,0,0), (1,0,0), (2,0,0), (3,0,0) ....,(nx-1,ny-1,0)\n",
    "        obj_pnts = np.zeros((nx*ny,3), np.float32)\n",
    "        obj_pnts[:,:2] = np.mgrid[0:nx,0:ny].T.reshape(-1,2)\n",
    "\n",
    "        for img_name in images:\n",
    "            img = cv2.imread(img_name)    \n",
    "            gr_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "            \n",
    "            # Identigfying corners on a gray scaled chess image\n",
    "            ret, corners = cv2.findChessboardCorners(gr_img, (nx, ny), None)\n",
    "\n",
    "            if ret == True:\n",
    "                imgpoints.append(corners) # storing positions (pixels) of identified corners \n",
    "                objpoints.append(obj_pnts)\n",
    "                img = cv2.drawChessboardCorners(img, (nx, ny), corners, ret)\n",
    "\n",
    "        self.ret, self.mtx, self.dist, self.rvecs, self.tvecs = cv2.calibrateCamera(objpoints, imgpoints, img.shape[1::-1], None, None)\n",
    "\n",
    "    \n",
    "    def undistort_image(self, img):\n",
    "        \"\"\"\n",
    "        Undistorts image using a computed calibration matrix.\n",
    "        \"\"\"\n",
    "        if self.mtx is None: \n",
    "            print('To undistor images compute first a calibratin matrix')\n",
    "            return None\n",
    "        else:\n",
    "            return cv2.undistort(img, self.mtx, self.dist, None, self.mtx)\n",
    "        \n",
    "    def perspective_transform(self, img):\n",
    "        \"\"\"\n",
    "        Applies a perspective transform to get \"birds-eye view\"\n",
    "        \"\"\"\n",
    "        M = cv2.getPerspectiveTransform(self.src, self.dst)\n",
    "        warped_img = cv2.warpPerspective(img, M, (img.shape[1],img.shape[0]), flags=cv2.INTER_NEAREST)\n",
    "\n",
    "        return warped_img\n",
    "    \n",
    "    def reverse_transform(self, wraped_img, img):\n",
    "        \"\"\"\n",
    "        Unwraps image using a computed reverse calibration matrix.\n",
    "        \"\"\"\n",
    "        Minv = cv2.getPerspectiveTransform(self.dst, self.src)\n",
    "        out_img = cv2.warpPerspective(wraped_img, Minv, (img.shape[1], img.shape[0])) \n",
    "        \n",
    "        return out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThresholdProcesser:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 k_size = 3, \n",
    "                 sh_thresh = (0,255), \n",
    "                 s_thresh = (0,255), \n",
    "                 m_thresh=(0,255), \n",
    "                 d_thresh=(0,1.5),\n",
    "                 l_thresh=(0,255)):\n",
    "        \n",
    "        self.kernel_size = k_size\n",
    "        self.s_channel_thresh = sh_thresh\n",
    "        self.sobel_abs_thresh = s_thresh \n",
    "        self.magnitude_thresh = m_thresh\n",
    "        self.direction_thresh = d_thresh\n",
    "        self.l_channel_thresh = l_thresh\n",
    "        \n",
    "    \n",
    "    def thresholds(self, img):\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        sobelx = cv2.Sobel(gray_img, cv2.CV_64F, 1, 0, self.kernel_size)\n",
    "        sobely = cv2.Sobel(gray_img, cv2.CV_64F, 0, 1, self.kernel_size) \n",
    "        \n",
    "        abs_soblex = np.absolute(sobelx)\n",
    "        abs_sobley = np.absolute(sobely)\n",
    "        \n",
    "        out_img = np.zeros_like(gray_img)\n",
    "        \n",
    "        dg = np.arctan2(abs_sobley, abs_soblex)\n",
    "        dg_c = (dg > self.direction_thresh[0]) & (dg < self.direction_thresh[1])\n",
    "        \n",
    "        abs_sobelxy = np.sqrt(np.power(sobelx,2) + np.power(sobely,2))\n",
    "        mg = np.uint8(255*abs_sobelxy/np.max(abs_sobelxy))\n",
    "        mg_c = (mg > self.magnitude_thresh[0]) & (mg < self.magnitude_thresh[1])\n",
    "        \n",
    "        scaled_sobelx = np.uint8(255*abs_soblex/np.max(abs_soblex))\n",
    "        absgx_c = (scaled_sobelx > self.sobel_abs_thresh[0]) & (scaled_sobelx < self.sobel_abs_thresh[1])\n",
    "        \n",
    "        scaled_sobely = np.uint8(255*abs_sobley/np.max(abs_sobley))\n",
    "        absgy_c = (scaled_sobely > self.sobel_abs_thresh[0]) & (scaled_sobely < self.sobel_abs_thresh[1])\n",
    "    \n",
    "        out_img[(absgx_c & absgy_c) | (mg_c & dg_c)] = 1 \n",
    "        \n",
    "        return out_img\n",
    "\n",
    "\n",
    "    def color_transform(self, img):\n",
    "\n",
    "        # Convert to HLS color space, separate and threshold the S channel\n",
    "        l_channel = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)[:,:,0]\n",
    "        s_channel = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)[:,:,2]\n",
    "        \n",
    "        c_binary_img = np.zeros_like(s_channel)\n",
    "        \n",
    "        s_channel_c = (s_channel >= self.s_channel_thresh[0]) & (s_channel <= self.s_channel_thresh[1])\n",
    "        l_channel_c = (l_channel >= self.l_channel_thresh[0]) & (l_channel <= self.l_channel_thresh[1])\n",
    "        \n",
    "        c_binary_img[s_channel_c & l_channel_c] = 1\n",
    "\n",
    "        return c_binary_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line:\n",
    "    def __init__(self):\n",
    "        self.detected = False  # was the line detected in the last iteration?\n",
    "        self.recent_xfitted = [] # x values of the last n fits of the line\n",
    "        self.bestx = [] #average x values of the fitted line over the last n iterations\n",
    "        self.best_fit = [] #polynomial coefficients averaged over the last n iterations\n",
    "        self.current_fit = [np.array([False])] #polynomial coefficients for the most recent fit\n",
    "        self.radius_of_curvature = None #radius of curvature of the line in some units\n",
    "        self.line_base_pos = None #distance of vehicle center from the center of lines\n",
    "        self.allx = None #x values for detected line pixels\n",
    "        self.ally = None #y values for detected line pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaneDetector:\n",
    "    \n",
    "    def __init__(self, nwindows, \n",
    "                 margin, \n",
    "                 minpix,\n",
    "                 n_frames=3):\n",
    "        \n",
    "        self.left_lane = Line()\n",
    "        self.right_lane = Line()\n",
    "        self.nwindows = nwindows\n",
    "        self.margin = margin\n",
    "        self.minpix = minpix\n",
    "        self.n_frames = n_frames\n",
    "\n",
    "    def fit_poly_for_lines(self, leftx, lefty, rightx, righty):\n",
    "        left_fit = np.polyfit(lefty, leftx, 2)\n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "        return left_fit, right_fit\n",
    "    \n",
    "    def generate_plotting_values(self, img):\n",
    "        \n",
    "        # Generate x and y values for plotting\n",
    "        ploty = np.linspace(0, img.shape[0]-1, img.shape[0])\n",
    "        l_best_fit = np.mean(self.left_lane.best_fit, axis=0)\n",
    "        r_best_fit = np.mean(self.right_lane.best_fit, axis=0)\n",
    "        left_fitx = l_best_fit[0]*(ploty)**2 + l_best_fit[1]*(ploty) + l_best_fit[2]\n",
    "        right_fitx = r_best_fit[0]*(ploty)**2 + r_best_fit[1]*(ploty) + r_best_fit[2]\n",
    "\n",
    "        return left_fitx, right_fitx\n",
    "\n",
    "    def find_lanes_w_histogram(self, binary_warped_img):\n",
    "    \n",
    "        # Take a histogram of the bottom half of the image\n",
    "        histogram = np.sum(binary_warped_img[binary_warped_img.shape[0]//2:,:], axis=0)\n",
    "        midpoint = np.int(histogram.shape[0]//2)\n",
    "\n",
    "        # Find the peak of the left and right halves of the histogram, starting point for the left and right lines\n",
    "        leftx_current = np.argmax(histogram[:midpoint])\n",
    "        rightx_current = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "        # Set height of windows - based on nwindows above and image shape\n",
    "        window_height = np.int(binary_warped_img.shape[0]//nwindows)\n",
    "\n",
    "        # Identify the x and y positions of all nonzero pixels in the image\n",
    "        nonzero = binary_warped_img.nonzero()\n",
    "        nzy = np.array(nonzero[0])\n",
    "        nzx = np.array(nonzero[1])\n",
    "\n",
    "        left_lane_inds = []\n",
    "        right_lane_inds = []\n",
    "\n",
    "        for window in range(self.nwindows):\n",
    "\n",
    "            # Identify window boundaries\n",
    "            win_y_low = binary_warped_img.shape[0] - (window+1)*window_height\n",
    "            win_y_high = binary_warped_img.shape[0] - window*window_height\n",
    "            win_xleft_low = leftx_current - self.margin  \n",
    "            win_xleft_high = leftx_current + self.margin\n",
    "            win_xright_low = rightx_current - self.margin\n",
    "            win_xright_high = rightx_current + self.margin\n",
    "\n",
    "            # We consider pixels which are within the height of the current window\n",
    "            rel_pix = (nzy < win_y_high) & (nzy >= win_y_low)\n",
    "            good_left_inds = (rel_pix & (nzx >= win_xleft_low) & (nzx < win_xleft_high)).nonzero()[0]    \n",
    "            good_right_inds = (rel_pix & (nzx < win_xright_high) & (nzx >= win_xright_low)).nonzero()[0] \n",
    "\n",
    "            # Append these indices to the lists\n",
    "            left_lane_inds.append(good_left_inds)\n",
    "            right_lane_inds.append(good_right_inds)\n",
    "\n",
    "            # If # of pixels > minpix pixels, we recenter next window\n",
    "            if len(good_left_inds) > self.minpix:\n",
    "                leftx_current = np.int(np.mean(nzx[good_left_inds]))\n",
    "\n",
    "            if len(good_right_inds) > self.minpix:        \n",
    "                rightx_current = np.int(np.mean(nzx[good_right_inds]))\n",
    "\n",
    "\n",
    "        # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "        # Extract left and right line pixel positions\n",
    "        self.left_lane.allx = nzx[left_lane_inds]\n",
    "        self.left_lane.ally = nzy[left_lane_inds] \n",
    "        self.right_lane.allx = nzx[right_lane_inds]\n",
    "        self.right_lane.ally = nzy[right_lane_inds]\n",
    "\n",
    "\n",
    "    def search_around_poly(self, b_warped_img):\n",
    "        # Grab activated pixels\n",
    "        nonzero = b_warped_img.nonzero()\n",
    "        nzy = np.array(nonzero[0])\n",
    "        nzx = np.array(nonzero[1])\n",
    "\n",
    "        left_fit = self.left_lane.current_fit\n",
    "        right_fit = self.right_lane.current_fit\n",
    "        \n",
    "        # Set the area of search based on activated x-values within the +/- margin of our polynomial function\n",
    "        left_lane_inds = ((nzx > (left_fit[0]*(nzy**2) + left_fit[1]*nzy + \n",
    "                        left_fit[2] - self.margin)) & (nzx < (left_fit[0]*(nzy**2) + \n",
    "                        left_fit[1]*nzy + left_fit[2] + self.margin)))\n",
    "        right_lane_inds = ((nzx > (right_fit[0]*(nzy**2) + right_fit[1]*nzy + \n",
    "                        right_fit[2] - self.margin)) & (nzx < (right_fit[0]*(nzy**2) + \n",
    "                        right_fit[1]*nzy + right_fit[2] + self.margin)))\n",
    "\n",
    "        # Extract left and right line pixel positions\n",
    "        self.left_lane.allx = nzx[left_lane_inds]\n",
    "        self.left_lane.ally = nzy[left_lane_inds] \n",
    "        self.right_lane.allx = nzx[right_lane_inds]\n",
    "        self.right_lane.ally = nzy[right_lane_inds]\n",
    "\n",
    "    def detect_lines_images(self, warped_image):\n",
    "        \n",
    "        self.find_lanes_w_histogram(warped_image)\n",
    "        left_fit, right_fit = self.fit_poly_for_lines(self.left_lane.allx, self.left_lane.ally, self.right_lane.allx, self.right_lane.ally)\n",
    "        self.left_lane.best_fit = [left_fit]\n",
    "        self.right_lane.best_fit = [right_fit]\n",
    "        left_fitx, right_fitx = self.generate_plotting_values(warped_image)\n",
    "        self.left_lane.bestx = left_fitx\n",
    "        self.right_lane.bestx = right_fitx\n",
    "        self.left_lane.best_fit.append(left_fit)\n",
    "        self.right_lane.best_fit.append(right_fit)\n",
    "            \n",
    "    def detect_lines_video(self, warped_image):\n",
    "\n",
    "        if not self.left_lane.detected: # If we could not detect the lanes, we start with histogram search \n",
    "            self.find_lanes_w_histogram(warped_image)\n",
    "        else: # In case we detected we search in the region of the line from the previous frame\n",
    "            self.search_around_poly(warped_image)\n",
    "\n",
    "        left_fit, right_fit = self.fit_poly_for_lines(self.left_lane.allx, self.left_lane.ally, self.right_lane.allx, self.right_lane.ally)\n",
    "        \n",
    "        ## Check that the detected lines are roughly paraller\n",
    "        ## or if its the first frame we anyways start with histogram search\n",
    "        if  np.abs(left_fit[0] - right_fit[0]) < 0.01  or not len(self.left_lane.bestx):\n",
    "            self.left_lane.detected = True\n",
    "            self.left_lane.current_fit = left_fit\n",
    "            \n",
    "            self.right_lane.detected = True\n",
    "            self.right_lane.current_fit = right_fit\n",
    "            \n",
    "            if len(self.left_lane.recent_xfitted) == self.n_frames:\n",
    "                self.left_lane.recent_xfitted.pop(0)\n",
    "                self.right_lane.recent_xfitted.pop(0)\n",
    "                self.left_lane.best_fit.pop(0)\n",
    "                self.right_lane.best_fit.pop(0)\n",
    "            \n",
    "            self.left_lane.best_fit.append(left_fit)\n",
    "            self.right_lane.best_fit.append(right_fit)\n",
    "            \n",
    "            left_curverad, right_curverad = self.measure_curvature(warped_image.shape[0])\n",
    "                \n",
    "            self.left_lane.radius_of_curvature = left_curverad\n",
    "            self.right_lane.radius_of_curvature = right_curverad\n",
    "            \n",
    "            self.left_lane.line_base_pos = self.find_lane_center(warped_image.shape[0], left_fit, right_fit)\n",
    "            \n",
    "            left_fitx, right_fitx = self.generate_plotting_values(warped_image)\n",
    "            \n",
    "            self.left_lane.recent_xfitted.append(left_fitx)\n",
    "            self.left_lane.bestx = np.mean(self.left_lane.recent_xfitted, axis=0).astype(int)\n",
    "            \n",
    "            self.right_lane.recent_xfitted.append(right_fitx)\n",
    "            self.right_lane.bestx = np.mean(self.right_lane.recent_xfitted, axis=0).astype(int)\n",
    "            \n",
    "        else:\n",
    "            self.left_lane.detected = False\n",
    "            self.right_lane.detected = False\n",
    "\n",
    "\n",
    "    def measure_curvature(self, h):\n",
    "        '''\n",
    "        Calculates the curvature of polynomial functions in meters.\n",
    "        '''\n",
    "        ploty = np.linspace(0, h-1, h, dtype=np.int32)                                              \n",
    "        y_eval = np.max(ploty)\n",
    "        \n",
    "        ym = 30/720 # meters per pixel in y dimension\n",
    "        xm = 3.7/700 # meters per pixel in x dimension\n",
    "        \n",
    "        left_fit_cr, right_fit_cr = self.fit_poly_for_lines(self.left_lane.allx*xm, self.left_lane.ally*ym, self.right_lane.allx*xm, self.right_lane.ally*ym)\n",
    "                                              \n",
    "        left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "        right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "        \n",
    "        return left_curverad, right_curverad\n",
    "    \n",
    "    def find_lane_center(self, h, left_fit, right_fit):\n",
    "        left_lane_c = left_fit[0]*h**2 + left_fit[1]*h + left_fit[2]\n",
    "        right_lane_c = right_fit[0]*h**2 + right_fit[1]*h + right_fit[2]\n",
    "        return left_lane_c + (right_lane_c - left_lane_c) /2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS\n",
    "nwindows = 9 # choose the number of sliding windows\n",
    "margin = 100 # set the width of the windows +/- margin\n",
    "minpix = 30 # set minimum number of pixels found to recenter window\n",
    "kernel_size = 5\n",
    "s_channel_thresh = (100, 255) \n",
    "sobel_abs_thresh = (10, 150) \n",
    "magnitude_thresh = (100, 255) \n",
    "direction_thresh = (0.7, 1.4)\n",
    "l_channel_thresh = (150, 255)\n",
    "\n",
    "src = np.float32([(678,443),(605,443),(285,665),(1019,665)]) # in x,y order not matrix convention\n",
    "dst = np.float32([(919,0),(285,0),(285,665),(919,665)])\n",
    "\n",
    "vehicle_center = (1240/2 - 285)/(1019 - 285)*(919 - 285) + 285\n",
    "\n",
    "## Computing camera calibration matrix and distortion coefficients\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "camera = Camera(src, dst)\n",
    "camera.compute_camera_calibration(images, 9, 6)\n",
    "\n",
    "threshold_processer = ThresholdProcesser(kernel_size, \n",
    "                                        s_channel_thresh,\n",
    "                                        sobel_abs_thresh,\n",
    "                                        magnitude_thresh,\n",
    "                                        direction_thresh,\n",
    "                                        l_channel_thresh) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-11-4b058cad76e7>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-11-4b058cad76e7>\"\u001b[1;36m, line \u001b[1;32m9\u001b[0m\n\u001b[1;33m    img_name = img_path.split('\\')[1]\u001b[0m\n\u001b[1;37m                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "def process_image(img_path, camera, threshold_processer, lane_detector):\n",
    "\n",
    "    # Undistort image using computed camera calibration matrix\n",
    "        \n",
    "    original_img = cv2.imread(img_path) \n",
    "    img = np.copy(original_img)\n",
    "    \n",
    "    print(img_path)\n",
    "    img_name = img_path.split('\\\\')[1]\n",
    "    folder_out = 'output_images\\'\n",
    "    \n",
    "    f, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1, 5, figsize=(25,10))\n",
    "    \n",
    "    undistorted_img = camera.undistort_image(img)\n",
    "    \n",
    "    ax1.set_title('Undistorted image', fontsize=20)\n",
    "    ax1.imshow(undistorted_img)\n",
    "    mpimg.imsave('{}undistort_{}'.format(folder_out, img_name), undistorted_img)\n",
    "        \n",
    "    # Applying color transforms and gradient thresholds to get a thresholded binary image\n",
    "    schbinary = threshold_processer.color_transform(img)\n",
    "    g_binary = threshold_processer.thresholds(img)\n",
    "    \n",
    "    # Combine the two binary thresholds\n",
    "    combined_binary = np.zeros_like(schbinary)\n",
    "    combined_binary[(schbinary == 1) | (g_binary == 1)] = 1\n",
    "    \n",
    "    ax2.set_title('Thresholded image', fontsize=20)\n",
    "    ax2.imshow(combined_binary, cmap='gray')\n",
    "    mpimg.imsave('{}binary_{}'.format(folder_out, img_name), combined_binary)\n",
    "    \n",
    "    b_warped_img = camera.perspective_transform(combined_binary)\n",
    "    \n",
    "    ax3.set_title('Warped image', fontsize=20)\n",
    "    ax3.imshow(b_warped_img, cmap='gray')\n",
    "    mpimg.imsave('{}warped_{}'.format(folder_out, img_name), b_warped_img)\n",
    "\n",
    "    lane_detector.detect_lines_images(b_warped_img)\n",
    "    \n",
    "    ax4.set_title('Detected lanes', fontsize=20)\n",
    "    ploty = np.linspace(0, img.shape[0]-1, img.shape[0], dtype=np.int32)\n",
    "    ax4.plot(lane_detector.left_lane.bestx, ploty, color='yellow')\n",
    "    ax4.plot(lane_detector.right_lane.bestx, ploty, color='yellow')\n",
    "    ax4.imshow(b_warped_img)\n",
    "    mpimg.imsave('{}warped_lines_{}'.format(folder_out, img_name), b_warped_img)\n",
    "        \n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(b_warped_img).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    ploty = np.linspace(0, img.shape[0]-1, img.shape[0], dtype=np.int32)\n",
    "    pts_left = np.array([np.transpose(np.vstack([lane_detector.left_lane.bestx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([lane_detector.right_lane.bestx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    \n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))    \n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = camera.reverse_transform(color_warp, img) \n",
    "    \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undistorted_img, 1, newwarp, 0.3, 0)\n",
    "    \n",
    "    ax5.set_title('Final image', fontsize=20)\n",
    "    ax5.imshow(result)\n",
    "    mpimg.imsave('{}final_{}'.format(folder_out, img_name), result)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_images\\straight_lines1.jpg\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-5ede60f5fafd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mout_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcamera\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold_processer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlane_detector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-a1c417d3b8a8>\u001b[0m in \u001b[0;36mprocess_image\u001b[1;34m(img_path, camera, threshold_processer, lane_detector)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mimg_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg_path\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mfolder_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'output_images/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "lane_detector = LaneDetector(nwindows, margin, minpix)\n",
    "\n",
    "test_images = glob.glob('test_images/*.jpg')\n",
    "\n",
    "for img_path in test_images:\n",
    "    out_img = process_image(img_path, camera, threshold_processer, lane_detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(image, camera, threshold_processer, lane_detector):\n",
    "\n",
    "    # Undistort image using computed camera calibration matrix\n",
    "    img = np.copy(image)\n",
    "    undistorted_img = camera.undistort_image(img)\n",
    "    \n",
    "    # Applying color transforms and gradient thresholds to get a thresholded binary image\n",
    "    schbinary = threshold_processer.color_transform(img)\n",
    "    g_binary = threshold_processer.thresholds(img)\n",
    "    \n",
    "    # Combine the two binary thresholds\n",
    "    combined_binary = np.zeros_like(schbinary)\n",
    "    combined_binary[(schbinary == 1) | (g_binary == 1)] = 1\n",
    "    \n",
    "    # Apply a perspective transform to rectify binary image (\"birds-eye view\")\n",
    "    b_warped_img = camera.perspective_transform(combined_binary)\n",
    "    \n",
    " \n",
    "    lane_detector.detect_lines_video(b_warped_img)\n",
    "    \n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(b_warped_img).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    ploty = np.linspace(0, img.shape[0]-1, img.shape[0], dtype=np.int32)\n",
    "    pts_left = np.array([np.transpose(np.vstack([lane_detector.left_lane.bestx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([lane_detector.right_lane.bestx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    \n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))  \n",
    "    cv2.polylines(color_warp, np.int_([pts_left]), isClosed=False, color=(255,0,0), thickness=30)\n",
    "    cv2.polylines(color_warp, np.int_([pts_right]), isClosed=False, color=(255,0,0), thickness=30)\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = camera.reverse_transform(color_warp, img) \n",
    "    \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undistorted_img, 1, newwarp, 0.3, 0)\n",
    "\n",
    "    #print(lane_detector.left_lane.radius_of_curvature, lane_detector.right_lane.radius_of_curvature)\n",
    "    curvature = 'Radius of curvature: {:0.1f} meters'.format((lane_detector.left_lane.radius_of_curvature+lane_detector.right_lane.radius_of_curvature) / 2)\n",
    "    cv2.putText(result, curvature, (50,50), cv2.FONT_HERSHEY_DUPLEX, 1.6, (255,255,255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    position = (vehicle_center - lane_detector.left_lane.line_base_pos) * 3.7/700\n",
    "    position_text = 'Vehicle is {:0.2f} meters {:s} of the center'.format(abs(position), 'left' if position < 0 else 'right') \n",
    "    cv2.putText(result, position_text, (50,100), cv2.FONT_HERSHEY_DUPLEX, 1.6, (255,255,255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    \n",
    "    #plt.imshow(result)\n",
    "    #plt.show()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "white_output = 'video_output\\project_video.mp4'\n",
    "lane_detector_v = LaneDetector(nwindows, margin, minpix)\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip1.fl_image(lambda x: process_video(x, camera, threshold_processer, lane_detector_v)) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"520\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
